Experiment with the settings of M and maxIter (or epsilon if you wish). For example, what happens to classification accuracy as the number of
components decreases? What about when the number of possible speakers, S, decreases? You will be marked on the detail with which you empirically
answer these questions and whether you can devise one or more additional valid experiments of this type.
    
1. What happens to classification accuracy as the number of components decreases?

 - For my experiment, I set the M to 8, 3, 1 respectively, and the accuracy for my is not that high as piazza says. When M=3 and M=8, the accuracy
   rate is around 60% and when M=1 the accuracy is around 50%. When M is decreasing, the function of UpdateParameters require extracting much less
   information than is needed to reconstruct entire training inputs. Sigma, which is the variance, getting to zero when less component provided.
   Therefore, the accuracy may decrease because of the underfitting of the data. Besides, when M is increasing, the training input optain more
   informations to reconstruct the matrix and will lead to data overfitting.

2. What about when the number of possible speakers, S, decreases?

 - Number of possible speakers decrease means that there are less examples provide in the training session. It is surprisingly that if I randomly
   choose only 3 speakers from the whole 32 speakers data set, I will get the highest accuracy than other amount of random choose speakers. In this
   test I am using 3 speakers, 10 speakers, 32 speakers to run the train-test cycle. The reason why there exist difference between different amount
   of the accuracy is because of the data overfitting problem. The larger the data set is, the more latent variable it need to deal with, the bigger
   the error will be generated by the model.

    Additionally, your report should include short hypothetical answers to the following questions:
    1. How might you improve the classification accuracy of the Gaussian mixtures, without adding more training data?

     - The way to improve the classification accuracy of the Gaussian mixtures without adding more training data is to set a much lowerepsilon (> 0)
       and set a higher max iteration number. Since the M=8 can provide best accuracy, thus we just keep it.


    2. When would your classifier decide that a given test utterance comes from none of the trained speaker models,
       and how would your classifier come to this decision?

     - As we have a set of k-best speaker and their log-likelihood, we firstly pick the BEST speaker's log-likelihood value and use it to compare with
       other speaker's log-likelihood values. If the BEST speaker's log-likelihood value is significantly better than other speaker's log-likelihood
       values, we can conclude that the utterance is from the BEST speaker in this set. On the other hand, if we found the BEST speaker's log-likelihood
       value is not significantly better than other speaker's log-likelihood values, we can conclude that the given test utterance comes from none of the
       trained speaker models since the variance (Sigma) is small.


    3. Can you think of some alternative methods for doing speaker identification that don't use Gaussian mixtures?

     - As the knowledge from slides, we can replace GMMs with ANN, especially (LTSM) RNN. Neural networks (feedforward or RNN) are typically
       trained as frame-level classifiers. It required alignment between the audio and the transcription during the training session. Then the
       second step of RNN is needing an objective function that allows sequence transcription without requiring prior alignment between the
       input and target sequences.
